{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install Dependencies and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (3.6.3)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-gpu pandas matplotlib sklearn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('jigsaw-toxic-comment-classification-challenge','train.csv', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.head(60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df['comment_text']\n",
    "y = df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_FEATURES = 200000 # number of words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
    "                               output_sequence_length=1800,\n",
    "                               output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorized_text = vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.7))\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_FEATURES+1, 32))\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          6400032   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                16640     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 6,491,686\n",
      "Trainable params: 6,491,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2625/2625 [==============================] - 662s 250ms/step - loss: 0.1116 - val_loss: 0.0502\n",
      "Epoch 2/5\n",
      "2625/2625 [==============================] - 605s 231ms/step - loss: 0.0503 - val_loss: 0.0444\n",
      "Epoch 3/5\n",
      "2625/2625 [==============================] - 647s 247ms/step - loss: 0.0426 - val_loss: 0.0394\n",
      "Epoch 4/5\n",
      "2625/2625 [==============================] - 619s 236ms/step - loss: 0.0384 - val_loss: 0.0355\n",
      "Epoch 5/5\n",
      "2625/2625 [==============================] - 848s 323ms/step - loss: 0.0353 - val_loss: 0.0329\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs=5, validation_data=val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text = vectorizer(['I will kill you!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = model.predict(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(res > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(batch_X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "    # Unpacking the batch \n",
    "    x_true, y_true = batch\n",
    "    yhat = model.predict(x_true)\n",
    "    \n",
    "    # Flatten the predictions\n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    # Update the metrics\n",
    "    pre.update_state(y_true, yhat)\n",
    "    re.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8733960390090942, Recall:0.7647939920425415, Accuracy:0.5306666493415833\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test and Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting anyio<5.0,>=3.0 (from gradio)\n",
      "  Downloading anyio-4.5.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting fastapi<1.0 (from gradio)\n",
      "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.3.0 (from gradio)\n",
      "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting huggingface-hub>=0.19.3 (from gradio)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting jinja2<4.0 (from gradio)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from gradio) (3.6.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from gradio) (1.19.2)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.10-cp38-none-win_amd64.whl.metadata (51 kB)\n",
      "     ---------------------------------------- 0.0/51.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 51.8/51.8 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from gradio) (24.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from gradio) (1.2.5)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from gradio) (10.3.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.16-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyyaml<7.0,>=5.0 (from gradio)\n",
      "  Downloading PyYAML-6.0.2-cp38-cp38-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.7.1-py3-none-win_amd64.whl.metadata (25 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting typing-extensions~=4.0 (from gradio)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from gradio) (2.2.1)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Using cached uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fsspec (from gradio-client==1.3.0->gradio)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
      "  Downloading websockets-12.0-cp38-cp38-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Collecting sniffio>=1.1 (from anyio<5.0,>=3.0->gradio)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio<5.0,>=3.0->gradio)\n",
      "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi<1.0->gradio)\n",
      "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.19.3->gradio)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.19.3->gradio)\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.23.4-cp38-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-13.9.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.15.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\face\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
      "   ---------------------------------------- 0.0/18.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/18.1 MB 3.3 MB/s eta 0:00:06\n",
      "   ---------------------------------------- 0.2/18.1 MB 1.8 MB/s eta 0:00:11\n",
      "    --------------------------------------- 0.3/18.1 MB 2.6 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.6/18.1 MB 3.1 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.9/18.1 MB 3.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.4/18.1 MB 4.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.0/18.1 MB 6.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.8/18.1 MB 7.3 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.9/18.1 MB 9.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 5.0/18.1 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 6.1/18.1 MB 11.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 6.5/18.1 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 6.5/18.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 8.5/18.1 MB 13.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 10.7/18.1 MB 18.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 11.8/18.1 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 13.0/18.1 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 14.1/18.1 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 15.2/18.1 MB 23.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 16.3/18.1 MB 23.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 17.4/18.1 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.1/18.1 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.1/18.1 MB 26.2 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "   ---------------------------------------- 0.0/318.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 318.7/318.7 kB ? eta 0:00:00\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading anyio-4.5.2-py3-none-any.whl (89 kB)\n",
      "   ---------------------------------------- 0.0/89.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 89.8/89.8 kB ? eta 0:00:00\n",
      "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
      "   ---------------------------------------- 0.0/94.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 94.7/94.7 kB ? eta 0:00:00\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.0/78.0 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "   ---------------------------------------- 0.0/447.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 447.5/447.5 kB 27.3 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.3/133.3 kB ? eta 0:00:00\n",
      "Downloading orjson-3.10.10-cp38-none-win_amd64.whl (138 kB)\n",
      "   ---------------------------------------- 0.0/139.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.0/139.0 kB ? eta 0:00:00\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp38-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.9 MB 3.6 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/1.9 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 8.2 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.16-py3-none-any.whl (24 kB)\n",
      "Downloading PyYAML-6.0.2-cp38-cp38-win_amd64.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/162.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 162.7/162.7 kB 9.5 MB/s eta 0:00:00\n",
      "Downloading ruff-0.7.1-py3-none-win_amd64.whl (9.4 MB)\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/9.4 MB 28.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.3/9.4 MB 29.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.3/9.4 MB 29.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.3/9.4 MB 29.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.1/9.4 MB 25.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.6/9.4 MB 25.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.4 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.4 MB 25.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.4/9.4 MB 23.1 MB/s eta 0:00:00\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.3/47.3 kB 2.3 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "   ---------------------------------------- 0.0/179.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 179.6/179.6 kB 10.6 MB/s eta 0:00:00\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading rich-13.9.3-py3-none-any.whl (242 kB)\n",
      "   ---------------------------------------- 0.0/242.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 242.2/242.2 kB 14.5 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.3/73.3 kB ? eta 0:00:00\n",
      "Downloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB ? eta 0:00:00\n",
      "Downloading websockets-12.0-cp38-cp38-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.0/125.0 kB ? eta 0:00:00\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pydub, websockets, typing-extensions, tqdm, tomlkit, sniffio, shellingham, semantic-version, ruff, pyyaml, python-multipart, orjson, mdurl, jinja2, importlib-resources, h11, fsspec, filelock, ffmpy, exceptiongroup, click, aiofiles, uvicorn, pydantic-core, markdown-it-py, huggingface-hub, httpcore, anyio, annotated-types, starlette, rich, pydantic, httpx, typer, gradio-client, fastapi, gradio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 anyio-4.5.2 click-8.1.7 exceptiongroup-1.2.2 fastapi-0.115.4 ffmpy-0.4.0 filelock-3.16.1 fsspec-2024.10.0 gradio-4.44.1 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 huggingface-hub-0.26.2 importlib-resources-6.4.5 jinja2-3.1.4 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.10.10 pydantic-2.9.2 pydantic-core-2.23.4 pydub-0.25.1 python-multipart-0.0.16 pyyaml-6.0.2 rich-13.9.3 ruff-0.7.1 semantic-version-2.10.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.41.2 tomlkit-0.12.0 tqdm-4.66.6 typer-0.12.5 typing-extensions-4.12.1 uvicorn-0.32.0 websockets-12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.1 requires typing-extensions~=3.7.4, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "tensorflow-gpu 2.4.1 requires typing-extensions~=3.7.4, but you have typing-extensions 4.12.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\face\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('toxicity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('toxicity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_str = vectorizer(['I hate you'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = model.predict(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.750397  , 0.01599535, 0.10396325, 0.04523145, 0.23077859,\n",
       "        0.07680876]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score(comment):\n",
    "    vectorized_comment = vectorizer([comment])\n",
    "    results = model.predict(vectorized_comment)\n",
    "    \n",
    "    text = ''\n",
    "    for idx, col in enumerate(df.columns[2:]):\n",
    "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn=score, \n",
    "                         inputs=gr.Textbox(lines=2, placeholder='Comment to score'),\n",
    "                        outputs='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
